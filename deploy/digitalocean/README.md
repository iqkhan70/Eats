# Deploy Kram to DigitalOcean

Deploy with **HTTPS at the edge** and **HTTP inside** a private network. Same one-command pattern as the mental health app: put your Droplet IP in a file, run the script, and the app is ready.

## One-command deploy (Droplet)

1. Create a Droplet. **Use at least 4 GB RAM; 8 GB recommended** (see [Droplet size and memory](#droplet-size-and-memory-oom-lockup) below). Docker one-click or Ubuntu + Docker. Note its IP.
2. Put the IP in a file (one-time):
   ```bash
   cp DROPLET_IP.example DROPLET_IP
   # Edit DROPLET_IP and replace YOUR_DROPLET_IP with your IP, e.g. 1.2.3.4
   # Or: echo '1.2.3.4' > DROPLET_IP
   ```
3. Run:
   ```bash
   ./deploy.sh
   ```
   The script will:
   - Load `DROPLET_IP` from the file
   - Test SSH and install Docker on the droplet if needed
   - Create `.env` on the server (generates passwords if first run; reuses existing if redeploying)
   - Copy compose, nginx config, and scripts to `/opt/kram`
   - Pull images and start the stack
   - Create all MySQL databases
     After that, open **http://&lt;your-droplet-ip&gt;** and the app is ready.

**No .env editing required** for first deploy. Secrets (MYSQL_ROOT_PASSWORD, JWT_SECRET, RABBITMQ_PASSWORD) are generated by the script on the server. Optional: create `secrets.env` from `secrets.env.example` to set REGISTRY/DIGITALOCEAN_ACCESS_TOKEN for build/push, or EMAIL/Stripe overrides.

### Staging / production

The same **docker-compose.prod.yml** is used for both; the deploy script sets **ASPNETCORE_ENVIRONMENT** in the server `.env` (Staging vs Production) based on which target you use.

- **Single environment:** Use `DROPLET_IP` (default). Run `./deploy.sh`. → `ASPNETCORE_ENVIRONMENT=Production`
- **Staging:** Create `DROPLET_IP_STAGING` with the staging Droplet IP. Run `./deploy.sh staging`. → `ASPNETCORE_ENVIRONMENT=Staging`
- **Production:** Create `DROPLET_IP_PRODUCTION` with the production Droplet IP. Run `./deploy.sh production`. → `ASPNETCORE_ENVIRONMENT=Production`

**Domain configuration:** Set `PRODUCTION_BASE_URL` and `PRODUCTION_DOMAIN` in `secrets.env` for production. The script automatically:

- Uses `PRODUCTION_BASE_URL` for the app base URL (defaults to `http://DROPLET_IP` if not set)
- Extracts domain from `PRODUCTION_BASE_URL` if `PRODUCTION_DOMAIN` is not set
- Generates `CORS_ALLOWED_ORIGINS` from the domain (includes both `www.` and non-`www.` variants)
- Configures Nginx and all services to use the production domain

Example for production:

```bash
PRODUCTION_BASE_URL=https://www.kram.tech
PRODUCTION_DOMAIN=www.kram.tech
```

**If https://&lt;droplet-ip&gt; works but http://www.kram.tech or https://www.kram.tech shows nginx 404 or an error:** the domain is almost certainly pointing at a different server. Fix DNS first:

- **A record for `www.kram.tech`** → your production droplet IP (e.g. `104.236.116.189`)
- **A record for `kram.tech`** (optional but recommended) → same IP

Check from your machine: `dig www.kram.tech +short` (or `nslookup www.kram.tech`). The result must be your production droplet IP. Until DNS points to the same box, the domain will hit another host (e.g. old droplet or parked page) and show nginx errors there. After updating DNS, wait for TTL (a few minutes to an hour) and try again.

## Prerequisites

- DigitalOcean account: a Droplet (and optionally Container Registry)
- SSH access to the Droplet (key-based; default key: `~/.ssh/id_rsa`, or set `SSH_KEY_PATH` in `secrets.env`)
- [doctl](https://docs.digitalocean.com/reference/doctl/how-to/install/) optional (for App Platform only)

## Droplet size and memory (OOM lockup)

This stack runs **many services** (MySQL, Redis, RabbitMQ, 12 .NET apps, Ollama, Nginx). On a **4 GB Droplet** the deploy script now:

- **Creates a 2 GB swap file** on the server so the system can swap instead of locking up when memory is tight.
- **Build-on-server builds one image at a time** (`COMPOSE_PARALLEL_LIMIT=1`) so parallel `dotnet restore` doesn’t exhaust RAM.
- **Sets memory limits** on each container in `docker-compose.prod.yml` so no single service can consume all RAM.

If the Droplet still locks up (SSH stops responding, deploy hangs):

- **Use 8 GB RAM** for a comfortable margin.
- Use **`./deploy.sh build-on-server`** (not `./deploy.sh` with pull) so builds run sequentially on the server.
- After lockup, wait a few minutes and try SSH again; if the OOM killer ran, the box may recover once memory is freed.

## What the deploy script does

- **`./deploy.sh`** (no args): Full deploy using `DROPLET_IP` file. Installs Docker on droplet if needed, creates .env on server, copies files, starts stack, runs MySQL init.
- **`./deploy.sh staging`** / **`./deploy.sh production`**: Same as above using `DROPLET_IP_STAGING` or `DROPLET_IP_PRODUCTION`.
- **`./deploy.sh build-on-server`**: Sync repo to Droplet, build **on the server**, push to DOCR (if REGISTRY+token set), then pull and up. Like mental health app; ~15–30 min. No build on your Mac.
- **`./deploy.sh staging`** / **`./deploy.sh production`**: Deploy only – copy files, DOCR login, pull, up. **~5 min.** Images must already be in the registry (from a previous build-on-server or CI).
- **`./deploy.sh setup-https [staging|production] [domain]`**: Get Let's Encrypt certificates and enable HTTPS. Examples: `./deploy.sh setup-https staging www.caseflowstage.store`, `./deploy.sh setup-https production www.kram.tech`. If you pass `<domain>`, it is used; otherwise domain is read from server `.env`.
- **`./deploy.sh build`**: Build and push **on your Mac** (slow on Apple Silicon). Use only for CI or one-off; prefer build-on-server.
- **`./deploy.sh app-platform`**: Create/update App Platform app from `app-spec.yaml` (requires doctl and `APP_ID`).

## Two deploy flows (why staging “takes forever” and why the registry is empty)

| Flow                | Command                                           | Where build runs                                                           | Pushes to DOCR?                          | When to use                                                                                                                       |
| ------------------- | ------------------------------------------------- | -------------------------------------------------------------------------- | ---------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------- |
| **Deploy (pull)**   | `./deploy.sh staging` or `./deploy.sh production` | If `REGISTRY` + token are set: **on your Mac** first (then droplet pulls). | Yes (if build ran).                      | You want images in the registry and can wait for a local build, or you use `SKIP_BUILD=1` and images are already in the registry. |
| **Build on server** | `./deploy.sh build-on-server`                     | **On the Droplet** (native amd64).                                         | **No.** Images stay on the Droplet only. | You’re on a Mac/ARM and don’t want a 1–2+ hour local build; you’re fine with images only on the server.                           |

- **`./deploy.sh staging` “taking forever”:** With `REGISTRY` and `DIGITALOCEAN_ACCESS_TOKEN` in `secrets.env`, the script **builds on your Mac** before deploying. On Apple Silicon that build is very slow (1–2+ hours). Use **`SKIP_BUILD=1 ./deploy.sh staging`** to skip the local build and only deploy (copy files, pull from registry, start). Or use **`./deploy.sh build-on-server`** so the build runs on the Droplet.
- **Nothing in DigitalOcean registry after build-on-server:** **build-on-server does not push** to the registry. It builds on the Droplet and runs the stack there. The registry only gets images if you run **`./deploy.sh build`** (local build + push) or your CI pushes.

## Optional: build and push images (local / CI)

If you ever want to build **on your Mac** and push (e.g. for CI): copy `secrets.env.example` to `secrets.env`, set `REGISTRY` and `DIGITALOCEAN_ACCESS_TOKEN`, run `./deploy.sh build` (slow on Mac/ARM), then `./deploy.sh staging`. Prefer **`./deploy.sh build-on-server`** so the build runs on the Droplet and pushes; then **`./deploy.sh staging`** is ~5 min.

## HTTPS: staging (HTTP + HTTPS) and production (HTTPS only)

- **Staging** (`./deploy.sh staging`): Nginx serves **both HTTP (80) and HTTPS (443)**. Use HTTPS when you have a domain and certs; HTTP remains available (e.g. `http://165.227.182.46`).
- **Production** (`./deploy.sh production`): **HTTPS only**. HTTP (80) redirects to HTTPS; the front end is served only over HTTPS.

**Production and self-signed cert:** So that the app works as soon as you deploy (and to avoid 404s when no Let's Encrypt cert exists yet), production deploy creates a **self-signed certificate** in `nginx/ssl/` and configures Nginx to serve HTTPS with it. The browser will show a security warning (e.g. "Your connection is not private"); you can proceed to the site. To get a trusted cert and remove the warning, run **`./deploy.sh setup-https production www.kram.tech`** (or your domain), then regenerate nginx with `CERTS_READY=1` as in the setup-https instructions.

To enable **trusted** HTTPS (Let's Encrypt) you need a **domain** (Let's Encrypt does not issue certs for raw IPs) and **certificates**:

1. **Point a domain at your Droplet** (e.g. staging: `staging.yourdomain.com` or `www.caseflowstage.store` → staging IP; production: `yourdomain.com` → production IP).
2. **Get a certificate** on the server (once Nginx and the stack are running with HTTP):
   ```bash
   # On the server (or from a one-off certbot container using certbot_www/certbot_certs volumes)
   docker run --rm -v kram_certbot_www:/var/www/certbot -v kram_certbot_certs:/etc/letsencrypt certbot/certbot certonly --webroot -w /var/www/certbot -d YOUR_STAGING_DOMAIN
   ```
3. **Set domain and base URL** in `secrets.env`:
   - Staging: `STAGING_BASE_URL=https://www.caseflowstage.store`, `STAGING_DOMAIN=www.caseflowstage.store` (or leave empty to use HTTP only).
   - Production: `PRODUCTION_BASE_URL=https://your-prod-domain.com`, `PRODUCTION_DOMAIN=your-prod-domain.com`.
4. **Redeploy** so the script regenerates nginx.conf with SSL and the correct redirect (production: HTTP→HTTPS only).

If `DOMAIN` is empty (e.g. you use only an IP), Nginx stays HTTP-only. The generated config is in `scripts/generate-nginx-conf.sh` (driven by `DOMAIN` and `HTTPS_ONLY`).

### HTTPS not working? (step-by-step)

1. **Use a domain, not an IP** – Let's Encrypt does not issue certs for raw IPs. Point a hostname (e.g. `www.caseflowstage.store` or `staging.yourdomain.com`) to your Droplet's IP in DNS.
2. **Deploy with HTTP first** – Run `./deploy.sh build-on-server` or `./deploy.sh staging` **without** setting `STAGING_DOMAIN` in `secrets.env` so the edge starts with HTTP only (no 443 block yet).
3. **Get a cert** – Run the setup command (domain auto-detected from server `.env`, or specify):
   ```bash
   ./deploy.sh setup-https staging www.caseflowstage.store
   ```
   Or manually on the server:
   ```bash
   ssh root@YOUR_DROPLET_IP
   cd /opt/kram
   bash deploy/digitalocean/scripts/setup-https.sh www.caseflowstage.store
   ```
   This runs certbot (using the same Docker volumes as the stack), regenerates nginx.conf with HTTPS for that domain, and restarts the edge container.
4. **Set domain for future deploys** – In `secrets.env` add `STAGING_DOMAIN=www.caseflowstage.store` and `STAGING_BASE_URL=https://www.caseflowstage.store` so the next deploy keeps HTTPS.
5. **Test** – Open `https://www.caseflowstage.store` (or your domain). If you see certificate errors, DNS may not point to this server yet or certbot failed (check script output).

## Optional: override server .env

Create `secrets.env` and set any of: `APP_BASE_URL`, `STAGING_DOMAIN`, `PRODUCTION_DOMAIN`, `EMAIL_MAILGUN_API_KEY`, `EMAIL_MAILGUN_DOMAIN`, `STRIPE_SECRET_KEY`, `STRIPE_WEBHOOK_SECRET`. These are written into the server `.env` when you run `./deploy.sh`. Otherwise the script uses defaults (e.g. `APP_BASE_URL=http://&lt;DROPLET_IP&gt;`).

## MySQL databases

The script runs `deploy/digitalocean/scripts/mysql-init.sh` on the server after `docker compose up -d`, creating all required databases (identity, customer, order, catalog, notification, restaurant, payment, chat, ai, review, document) if they don't exist. Each service runs EF migrations on startup. If init fails (e.g. MySQL not ready yet), on the server run: `cd /opt/kram && bash deploy/digitalocean/scripts/mysql-init.sh`.

**MySQL is exposed on port 3306** for direct access from your Mac. Connect using:

- **Host:** Your Droplet IP (e.g. `165.227.182.46`)
- **Port:** `3306`
- **User:** `root`
- **Password:** Value of `MYSQL_ROOT_PASSWORD` from your server `.env` file

Example connection string: `server=165.227.182.46;port=3306;user=root;password=YOUR_PASSWORD`

## Admin user seeding

After database creation, the deploy script automatically seeds an admin user (enabled by default):

- **Email:** `admin@kram.com` (default, configurable via `ADMIN_EMAIL` in `secrets.env`)
- **Password:** `Admin123!` (default, **change this in production** via `ADMIN_PASSWORD` in `secrets.env`)
- **Role:** Admin (full system access)

**To customize:** Add to `secrets.env`:

```bash
ADMIN_EMAIL=your-admin@example.com
ADMIN_PASSWORD=YourSecurePassword123!
SEED_ADMIN=true  # Set to false to skip seeding
```

**DocumentService (vendor documents):** The `document-service` container stores uploaded files in **DigitalOcean Spaces** (S3-compatible). Set `DIGITALOCEAN_SPACES_*` in `secrets.env` (see `secrets.env.example`) so uploads work. The document database (`traditional_eats_document`) is created by `mysql-init.sh`; the service runs EF migrations on startup.

**To seed manually:** On the server:

```bash
cd /opt/kram
bash deploy/digitalocean/scripts/seed-admin.sh [email] [password]
```

The script is idempotent - it won't create duplicates if the admin user already exists, but will ensure the Admin role is assigned.

## App Platform

See `APP_PLATFORM.md`. Build and push images, edit `app-spec.yaml`, then run `./deploy.sh app-platform`.

## Troubleshooting

### 401 Unauthorized when pulling images

Docker is trying to pull from DigitalOcean Container Registry without being logged in.

- **If you use `./deploy.sh`:** The script logs the Droplet into DOCR using `DIGITALOCEAN_ACCESS_TOKEN`. Ensure `deploy/digitalocean/secrets.env` exists and contains:
  - `DIGITALOCEAN_ACCESS_TOKEN=<your DO API token>`
  - `REGISTRY=registry.digitalocean.com/cha-registry` (or your registry name)
    Create `secrets.env` from `secrets.env.example`; get a token from DigitalOcean Control Panel → API → Tokens/Keys.
- **If you run `docker compose pull` or `docker compose up` locally** (e.g. to test prod compose): log in first:
  ```bash
  echo "$DIGITALOCEAN_ACCESS_TOKEN" | docker login registry.digitalocean.com -u "$DIGITALOCEAN_ACCESS_TOKEN" --password-stdin
  ```
  Then run your compose command with the same `REGISTRY`/`REPO_NAME` in `.env`.

### 502 Bad Gateway when pushing to DOCR (attestation)

Push fails with `502 Bad Gateway` on PUTs to `.../blobs/uploads/...attestation-sha256...`. Docker Buildx pushes **provenance attestations** by default; some registries (including DOCR under load) can 502 on those.

The deploy script now sets **`BUILDX_NO_DEFAULT_ATTESTATIONS=1`** for both local and server builds so attestations are not created and push should succeed. If you still see 502, build and push with attestations disabled manually:

```bash
BUILDX_NO_DEFAULT_ATTESTATIONS=1 docker compose -f deploy/digitalocean/docker-compose.prod.yml --env-file .env build
# then push as usual
```

### 503 Service Unavailable when pulling from DOCR

Pull fails with `503 Service Unavailable` from `nyc3.digitaloceanspaces.com`. This is a **DigitalOcean Container Registry infrastructure issue** (temporary unavailability or rate limiting), not a code problem.

**The deploy script now retries pulls automatically (3 attempts).** If it still fails:

**Option 1 – Skip pull, use existing images:**

```bash
# On server, if images are already there from a previous build-on-server:
cd /opt/kram
docker compose -f deploy/digitalocean/docker-compose.prod.yml --env-file .env up -d
```

**Option 2 – Use build-on-server (no registry pull needed):**

```bash
./deploy.sh build-on-server staging
# This builds on the server, so no pull from DOCR is needed
```

**Option 3 – Wait and retry:**
DOCR 503s are usually temporary. Wait 5–10 minutes and run `./deploy.sh staging` again.

### 520 / 5xx errors when pushing to DOCR

Push fails with `520` or other `5xx` status codes when uploading layers to DOCR. This is a **DigitalOcean Container Registry infrastructure issue** (temporary unavailability, rate limiting, or network issues), not a code problem.

**The deploy script now retries pushes automatically (3 attempts with 15s delays).** If it still fails:

**What happens:**

- Some images may have been pushed successfully (partial success)
- The same layer may fail across multiple services if it's a shared base layer
- DOCR may be experiencing temporary issues with that specific blob

**Options:**

**Option 1 – Retry the push:**

```bash
# On server, retry pushing:
cd /opt/kram
export BUILDX_NO_DEFAULT_ATTESTATIONS=1
docker compose -f deploy/digitalocean/docker-compose.prod.yml --env-file .env push
```

**Option 2 – Continue deployment (images already on server):**
If you used `build-on-server`, the images are already on the Droplet, so you can skip the push and continue:

```bash
# On server:
cd /opt/kram
docker compose -f deploy/digitalocean/docker-compose.prod.yml --env-file .env up -d
```

**Option 3 – Wait and retry:**
DOCR 520/5xx errors are usually temporary. Wait 5–10 minutes and retry the push or redeploy.

### Droplet locks up / SSH stops responding

The box is likely **out of memory (OOM)**. The deploy script now adds a 2 GB swap file, builds one image at a time on the server, and sets container memory limits. Prefer **8 GB RAM** for this stack, or use **`./deploy.sh build-on-server`** so builds run sequentially. See [Droplet size and memory](#droplet-size-and-memory-oom-lockup).

### cannot load certificate .../fullchain.pem (No such file or directory)

Nginx is configured for HTTPS with your domain but the Let's Encrypt certs don't exist yet. The deploy script now generates **HTTP-only** nginx when a domain is set (so Nginx can start); you then run `setup-https.sh` to obtain certs and switch to HTTPS.

**Fix now (on the server):**

- **Option A – Redeploy:** Run `./deploy.sh staging` (or your usual deploy) so the updated `generate-nginx-conf.sh` is copied; it will generate HTTP-only nginx and edge will start. Then on the server run `bash deploy/digitalocean/scripts/setup-https.sh www.caseflowstage.store` to get certs and enable HTTPS.

- **Option B – No redeploy:** Edit `deploy/digitalocean/nginx/nginx.conf` on the server and remove the entire `server { listen 443 ssl; ... }` block (the block that contains `ssl_certificate` and `listen 443`). Save, then restart edge (`docker compose -f deploy/digitalocean/docker-compose.prod.yml --env-file .env -p digitalocean up -d edge` if your project is `digitalocean`). Then run `bash deploy/digitalocean/scripts/setup-https.sh www.caseflowstage.store` to obtain certs and regenerate nginx with HTTPS.

After a **fresh deploy**, the generated nginx is already HTTP-only until you run `setup-https.sh <domain>`.

### HTTPS not working

See [HTTPS not working? (step-by-step)](#https-not-working-step-by-step) above: use a domain (not IP), deploy with HTTP first, then run `setup-https.sh <domain>` on the server. Ensure DNS points to the Droplet.

**If your server `.env` has `DOMAIN=https`:** That is wrong and breaks HTTPS (Nginx looks for certs at `/etc/letsencrypt/live/https/`). `DOMAIN` must be the **hostname only**, e.g. `www.caseflowstage.store`. Fix: in `secrets.env` set **`STAGING_DOMAIN=www.caseflowstage.store`** (not `https`), then redeploy so the server `.env` gets the correct DOMAIN. Or on the server: edit `/opt/kram/.env` and change `DOMAIN=https` to `DOMAIN=www.caseflowstage.store`, then run `bash deploy/digitalocean/scripts/setup-https.sh www.caseflowstage.store` (or regenerate nginx and restart edge).

### Wrong .env on production (e.g. Staging values causing edge to restart)

If the production server `.env` has staging values (e.g. `ASPNETCORE_ENVIRONMENT=Staging`, `APP_BASE_URL=https://www.caseflowstage.store`, `DOMAIN=www.caseflowstage.store`), nginx may look for the wrong certs and edge can restart in a loop.

**Fix on the server (no full deploy):**

1. SSH in and edit `/opt/kram/.env`. Set production values, for example:
   ```bash
   ASPNETCORE_ENVIRONMENT=Production
   APP_BASE_URL=https://www.kram.tech
   DOMAIN=www.kram.tech
   ```
2. Regenerate nginx (so it uses the correct DOMAIN/cert paths) and restart edge:
   ```bash
   cd /opt/kram
   source .env 2>/dev/null; export DOMAIN HTTPS_ONLY CERTS_READY=1
   bash deploy/digitalocean/scripts/generate-nginx-conf.sh > nginx/nginx.conf
   docker compose -f deploy/digitalocean/docker-compose.prod.yml --env-file .env up -d --force-recreate edge
   ```
3. If you only changed non-DOMAIN vars and don’t need to regenerate nginx, just restart so containers pick up the new `.env`:
   ```bash
   cd /opt/kram
   docker compose -f deploy/digitalocean/docker-compose.prod.yml --env-file .env up -d
   ```

Future runs of `./deploy.sh production` will write production values into `.env` (see deploy script).

### 502 Bad Gateway (after some time)

Nginx is up but the upstream (e.g. web-bff) is not responding – often a backend container crashed or was OOM-killed.

**On the Droplet (SSH in):**

```bash
cd /opt/kram   # or cd /opt/kram && docker compose -f deploy/digitalocean/docker-compose.prod.yml --env-file .env ps
docker compose -f deploy/digitalocean/docker-compose.prod.yml --env-file .env ps
```

Check for containers that are **Restarting** or **Exited**. Then check logs for the web app’s upstream (web-bff) and any unhealthy service:

```bash
docker compose -f deploy/digitalocean/docker-compose.prod.yml --env-file .env logs --tail=100 web-bff
docker compose -f deploy/digitalocean/docker-compose.prod.yml --env-file .env logs --tail=100 edge
```

If you see **OOMKilled** or out-of-memory in logs, the Droplet is short on RAM; use a larger Droplet (e.g. 8 GB) or reduce load. Restart the stack after fixing:

```bash
docker compose -f deploy/digitalocean/docker-compose.prod.yml --env-file .env up -d
```

### exec format error (entrypoint.sh)

Images were built for a different CPU architecture (e.g. ARM on Mac) but the Droplet is x86_64. Rebuild and push with the correct platform: the compose file now sets `platform: linux/amd64` for all app services. Run `./deploy.sh build` again (from your Mac), then redeploy so the Droplet pulls the new amd64 images.

## Security checklist

- [ ] Microservices are not exposed to the internet (only edge/WebApp).
- [ ] Inbound restricted to Nginx / load balancer (and SSH if needed).
- [ ] Do not commit `DROPLET_IP`, `DROPLET_IP_STAGING`, `DROPLET_IP_PRODUCTION`, or `secrets.env`.
- [ ] JWT secret and DB passwords are generated by the script; rotate if needed.
